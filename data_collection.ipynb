{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import keepa\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import keepa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function remove extra subcategories from each row and rename columns\n",
    "def clean_frame(df):\n",
    "    df = df.rename(columns = {'Title' : 'product_title', 'Categories: Sub' : 'subcategory', 'ASIN' : 'asin'})\n",
    "    def clean_row(row):\n",
    "        row['subcategory'] = row['subcategory'].split(',')[0].strip().lower()\n",
    "        return row\n",
    "    df = df.apply(clean_row, axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepa_time_to_datetime(kt):\n",
    "    # Convert Keepa time (minutes since 2011-01-01) to a Python datetime (UTC)\n",
    "    if isinstance(kt, datetime.datetime):\n",
    "        return kt\n",
    "    return datetime.datetime.fromtimestamp((kt + 21564000) * 60, datetime.timezone.utc)\n",
    "\n",
    "def generate_monthly_headers(days):\n",
    "    \"\"\"\n",
    "    Generate a list of month headers (strings) in the format 'YYYY-MM'\n",
    "    spanning from the current month back to the month that includes (now - days).\n",
    "    The headers are in ascending order. 2021-2025\n",
    "    This function standardizes which months we collect for each batch and ensures the columns are aligned.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now(datetime.timezone.utc)\n",
    "    start_date = now - datetime.timedelta(days=days)\n",
    "    \n",
    "    headers = []\n",
    "    current_year = now.year\n",
    "    current_month = now.month\n",
    "\n",
    "    while True:\n",
    "        header = f\"{current_year:04d}-{current_month:02d}\"\n",
    "        headers.append(header)\n",
    "        # Move to the previous month\n",
    "        if current_month == 1:\n",
    "            current_month = 12\n",
    "            current_year -= 1\n",
    "        else:\n",
    "            current_month -= 1\n",
    "        \n",
    "        # Create a timezone-aware date for the first day of the new month.\n",
    "        month_start = datetime.datetime(current_year, current_month, 1, tzinfo=datetime.timezone.utc)\n",
    "        # Stop if this month is before the start_date.\n",
    "        if month_start < start_date:\n",
    "            break\n",
    "    return sorted(headers)\n",
    "\n",
    "\n",
    "def get_monthly_avg_prices(asins, days=1460):\n",
    "    \"\"\"\n",
    "    asins: list of ASIN strings\n",
    "    days: number of days of history (default 1460 ~ 4 years)\n",
    "    \n",
    "    Returns a DataFrame:\n",
    "        - Rows = ASINs\n",
    "        - Columns = monthly time periods (e.g. '2025-02', '2025-01', etc.)\n",
    "        - Values = average 'NEW' price for that month\n",
    "    \"\"\"\n",
    "    products = api.query(asins, days=days)\n",
    "    dfs = []\n",
    "    for product in products:\n",
    "        asin = product['asin']\n",
    "        price_history = product['data'].get('NEW', [])\n",
    "        time_history  = product['data'].get('NEW_time', [])\n",
    "        \n",
    "        dates = [keepa_time_to_datetime(t) for t in time_history]\n",
    "        prices = [p for p in price_history]\n",
    "        \n",
    "        df = pd.DataFrame({'date': dates, asin: prices})\n",
    "        df.set_index('date', inplace=True)\n",
    "        \n",
    "        # Resample to monthly average using month-end frequency\n",
    "        monthly_avg = df.resample('ME').mean()\n",
    "        dfs.append(monthly_avg)\n",
    "    \n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine and transpose so that rows = ASIN and columns = dates\n",
    "    combined = pd.concat(dfs, axis=1).T\n",
    "    # Convert datetime columns to string format 'YYYY-MM'\n",
    "    combined.columns = [col.strftime('%Y-%m') for col in combined.columns]\n",
    "    \n",
    "    # Generate the complete set of monthly headers (headers are in descending order)\n",
    "    headers = generate_monthly_headers(days)\n",
    "    \n",
    "    # Reindex with headers generated headers\n",
    "    combined = combined.reindex(columns=headers, fill_value=np.nan)\n",
    "    \n",
    "    # Forward fill missing values along the row (in chronological order)\n",
    "    combined = combined.ffill(axis=1)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "def batch(iterable, n=20):\n",
    "    \"\"\"Yield successive n-sized chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_keepa_in_batches(products, category, max_batches=10, batch_size=20,\n",
    "                           days=365 * 4, start_index=0, stop_index=None):\n",
    "    \"\"\"\n",
    "    Query Keepa for monthly average prices in batches and incrementally save \n",
    "    the *merged* results (column-aligned) to a CSV file.\n",
    "    \"\"\"\n",
    "    # Slice the ASIN list based on start_index and stop_index.\n",
    "    asins = list(products['asin'])[start_index:stop_index]\n",
    "    csv_file = f'data/asin_prices/{category}_monthly_prices.csv'\n",
    "    for i, asin_batch in enumerate(batch(asins, batch_size)):\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "        df_batch = get_monthly_avg_prices(asin_batch, days=days)\n",
    "        if df_batch.empty:\n",
    "            print(f\"Batch {i+1} returned no data; skipping.\")\n",
    "            continue\n",
    "        # If the CSV file exists, read it, merge columns, then write back\n",
    "        if os.path.exists(csv_file):\n",
    "            existing_df = pd.read_csv(csv_file, index_col=0)\n",
    "            \n",
    "            # Merge on row index (ASIN) and combine columns (outer join).\n",
    "            # combine_first() will fill missing entries in existing_df with df_batch values.\n",
    "            merged_df = existing_df.combine_first(df_batch)\n",
    "            \n",
    "            # Ensure columns are in the correct order (descending monthly headers).\n",
    "            # This step uses the same monthly headers function to reindex.\n",
    "            headers = generate_monthly_headers(days)\n",
    "            merged_df = merged_df.reindex(columns=headers, fill_value=np.nan)\n",
    "            \n",
    "            merged_df.to_csv(csv_file, index=True)\n",
    "        else:\n",
    "            # If no CSV yet, just write df_batch as the first chunk\n",
    "            df_batch.to_csv(csv_file, index=True)\n",
    "        \n",
    "        print(f\"Batch {i+1} processed and merged.\")\n",
    "\n",
    "\n",
    "# Example helper function to split the ASIN list into batches.\n",
    "def batch(iterable, n=20): # 20 is default batch size\n",
    "    \"\"\"Yield successive n-sized chunks from iterable\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prices(df):\n",
    "    # Rename 'Unnamed: 0' to 'asin'\n",
    "    df = df.rename(columns={'Unnamed: 0': 'asin'})\n",
    "    \n",
    "    # Round every value in all columns except the first (asin) to 2 decimal places\n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:].round(2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = \"df2mtauj1tmrngcm95ubshd41fplpf2bfh1nba8s8hpd2m6golbbrj9bat7osb8o\" # do no share outside of private repo!!\n",
    "api = keepa.Keepa(ACCESS_KEY, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'toys'\n",
    "data_path = Path('data/keepa_data') / f'{category}.csv'\n",
    "products = pd.read_csv(data_path)\n",
    "products = clean_frame(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed and merged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:08<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 processed and merged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 processed and merged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:07<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 processed and merged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]Waiting 1186 seconds for additional tokens\n"
     ]
    }
   ],
   "source": [
    "query_keepa_in_batches(products, category, max_batches=25, batch_size=20, days = (365 * 5) + 60, start_index = 0, stop_index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path2 = Path('data/asin_prices') / f'{category}_monthly_prices.csv'\n",
    "price_data = pd.read_csv(data_path2)\n",
    "price_data = clean_prices(price_data)\n",
    "price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = list(price_data.columns[1:13]) + list(price_data.columns[-2:])\n",
    "price_data = price_data.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(products, price_data, on='asin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.dropna(subset=merged_data.columns[4:], how='all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
